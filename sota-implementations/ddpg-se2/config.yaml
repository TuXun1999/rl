# environment and task
env:
  name: SE2
  task: ""
  library: pendulum
  max_episode_steps: 1000
  seed: 42

# collector
collector:
  total_frames: 1_00_000
  init_random_frames: 1_000
  frames_per_batch: 400
  init_env_steps: 5000
  reset_at_each_iter: False
  device:
  env_per_collector: 4


# replay buffer
replay_buffer:
  size: 1000
  prb: 0 # use prioritized experience replay
  scratch_dir: null

# optimization
optim:
  utd_ratio: 1.0
  gamma: 0.99
  td_lambda: 0.9
  loss_function: l2
  actor_lr: 1.0e-4
  actor_weight_decay: 0.0
  critic_lr: 1.0e-3
  critic_weight_decay: 1e-2
  batch_size: 80
  target_update_polyak: 0.995
  device: null

# network
network:
  hidden_sizes: [256, 256]
  activation: relu
  noise_type: "ou" # ou or gaussian

compile:
  compile: False
  compile_mode:
  cudagraphs: False

# logging
logger:
  backend: wandb
  project_name: torchrl_example_ddpg
  group_name: null
  exp_name: ${env.name}_DDPG
  mode: online
  eval_iter: 2500
  video: False
  num_eval_envs: 1
