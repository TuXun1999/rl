# task and env
env:
  name: se2 
  task: ""
  library: "se2"
  seed: 42
  max_episode_steps: 40

# collector
collector:
  total_frames: 2_000
  prior_frames: 50 #1_0000
  init_random_frames: 0
  init_env_steps: 100 # NOT USED
  frames_per_batch: 25
  reset_at_each_iter: False
  device:
  env_per_collector: 1 # Somehow, I massed up the parallel env, and only one works
  num_workers: 1

# replay buffer
replay_buffer:
  prb: 0 # use prioritized experience replay
  size: 1000000
  scratch_dir: null

# optim
optim:
  utd_ratio: 1.0
  gamma: 0.99
  loss_function: l2
  lr: 3.0e-4
  weight_decay: 0.0
  adam_eps: 1e-4
  batch_size: 256
  target_update_polyak: 0.995
  policy_update_delay: 2
  policy_noise: 0.2
  noise_clip: 0.5

# network
network:
  hidden_sizes: [256, 256]
  activation: relu
  device: null

# logging
logger:
  backend: wandb
  project_name: torchrl_TD3_SE2
  group_name: null
  exp_name: ${env.name}_TD3
  mode: online
  eval_iter: 25
  video: False

compile:
  compile: False
  compile_mode:
  cudagraphs: False
